{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Tools for Medical Deep Learning\n",
    "### Special thanks to <a href=\"https://www.mayo.edu/research/labs/radiology-informatics/overview\">Dr. Bradley J. Erickson M.D., Ph.D.</a>, Department of Radiology, Mayo Clinic, for developing the MedNIST dataset\n",
    "#### Acknowledgements: Data derived from <a href=\"http://www.cancerimagingarchive.net/\">The Cancer Imaging Archive (TCIA)</a>; <a href =\"http://rsnachallenges.cloudapp.net/competitions/4\">Radiological Society of North America</a>; <a href= \"http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf\">National Institute of Health</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Advances in deep learning techniques combined with hardware advances such as GPU accelerated computing have led to new applications of artificial intelligence to the healthcare domain, particularly in the fields of radiology and genomics. However, deep learning relies on large, standardized datasets, and the algorithms can perform no better than the data they are provided. This lab will focus on techniques to prepare and augment radiological imaging datasets for use in deep neural networks.\n",
    "\n",
    "You will be guided through a basic series of exercises to normalize and augment an imaging dataset. While these steps will not apply to every task, this process is similar to what you might use to prepare your data. At the end, you will be able to download the augmented dataset you have created for use in your own deep learning projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Medical imaging presents both a unique opportunity for and a special challenge to deep learning. On the one hand, radiological imaging often involves both volumetric and time series data, providing 4-D datasets for analysis. The images produced tend to be high resolution, and there are often multiple imaging modalities applied to the same patient, providing richer datasets than in many other domains. On the other hand, gathering adequate samples for analysis can be difficult given the constraints of patient privacy and the rarity of some conditions. Also, even in the same imaging modality, devices originating from different manufacturers or different eras can produce subtly different scans that humans adapt to more easily than deep learning algorithms do. Therefore, it is important that we develop techniques to standardize and augment our datasets as necessary.\n",
    "\n",
    "### Import libraries\n",
    "The first step in this exercise is to import the code libraries needed. We work with PyTorch, a common framework for deep learning, as it has many built-in functions that allow us to perform complex image manipulations in a single line of code.\n",
    "\n",
    "Execute code blocks by highlighting them and pressing `Shift+Enter` or the run button above. Also, if you accidentally convert a text cell into its markdown (html-like code) format, `Shift+Enter` will convert it back to the formatted version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as mp\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import torch.utils.data as dat\n",
    "\n",
    "if torch.cuda.is_available():     # Make sure GPU is available\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "    kwar = {'num_workers': 8, 'pin_memory': True}\n",
    "    cpu = torch.device(\"cpu\")\n",
    "else:\n",
    "    print(\"Warning: CUDA not found, CPU only.\")\n",
    "    dev = torch.device(\"cpu\")\n",
    "    kwar = {}\n",
    "    cpu = torch.device(\"cpu\")\n",
    "\n",
    "np.random.seed(551)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make use of a modified version of the <a href=\"https://courses.nvidia.com/courses/course-v1:DLI+L-HX-07+V1/about\">MedNIST dataset</a> as our starting point. This dataset was prepared by aggregating images from the sources listed above, standardizing them to the same file format, and resizing them to the same dimensions. PyTorch also has <a href=\"https://pytorch.org/docs/stable/torchvision/transforms.html\">built-in functions</a> that can complete these tasks for us.\n",
    "\n",
    "Next, we examine the set of images that we have available. The images are sorted into categories, with a separate subdirectory for the files of each. The next codeblock identifies the number and names of image classes, then stores all the image file names and counts the individual members of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category ChestCT has 3912 images\n",
      "Category CXR has 773 images\n",
      "Category AbdomenCT has 1960 images\n",
      "Category Hand has 8437 images\n",
      "Category HeadCT has 7466 images\n",
      "Category BreastMRI has 6320 images\n"
     ]
    }
   ],
   "source": [
    "dataDir = 'imagedata'             # Location of image data\n",
    "classNames = os.listdir(dataDir)  # Creates list of class names\n",
    "numClass = len(classNames)        # Counts number of classses\n",
    "handClass = classNames.index('Hand')\n",
    "imageFiles = [[os.path.join(dataDir,classNames[i],x) for x in os.listdir(os.path.join(dataDir,classNames[i]))]\n",
    "              for i in range(numClass)]                       # list of all files\n",
    "numEach = [len(imageFiles[i]) for i in range(numClass)]       # Count of each image class\n",
    "imageWidth, imageHeight = Image.open(imageFiles[0][0]).size  # Image dimensions\n",
    "\n",
    "for i in range(numClass):\n",
    "    print(\"Category\",classNames[i],\"has\",numEach[i],\"images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are six different categories, but there are different numbers of each. When training a neural network, it is generally advantageous to have balanced numbers of each class; otherwise, the network tends to become biased toward choosing the more numerous category.\n",
    "\n",
    "We will explore data augmentation techniques to normalize the number of images in each category, but first, we take a look at some of the images available. The code block below can be run multiple times to sample different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.subplots(3,2,figsize=(8,8))\n",
    "for i in range(numClass): \n",
    "    im = Image.open(imageFiles[i][np.random.randint(numEach[i])])   # Randomly sample one image per class\n",
    "    arr = np.array(im)\n",
    "    mp.subplot(2,3,i+1)\n",
    "    mp.xlabel('Class: '+classNames[i])\n",
    "    mp.imshow(arr,cmap='gray',vmin=0,vmax=255)\n",
    "mp.tight_layout()\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the images are scaled differently than others - that is, they have different maximum and minimum brightness. Before performing the final set of augmentations, we will standardize the brightness of the images.\n",
    "\n",
    "However, let's explore how some different transformations look without this rescaling procedure. We start with `RandomRotation`, which, as the name suggests, rotates the image by a random number of degrees up to some maximum value in either direction. The unrotated image appears in the upper left corner.\n",
    "\n",
    "#### Exercise:\n",
    "Rerun the code block below multiple times, trying different maximum rotation values (change the value of `maxRot`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxRot = 30\n",
    "randRot = tv.transforms.RandomRotation(maxRot,resample=Image.BICUBIC)\n",
    "baseImage = Image.open(imageFiles[handClass][1])\n",
    "mp.subplots(3,3,figsize=(8,8))\n",
    "mp.subplot(3,3,1)\n",
    "mp.xlabel('Base Image')\n",
    "mp.imshow(np.array(baseImage),cmap='gray',vmin=0,vmax=255)\n",
    "for i in range(8):\n",
    "    randImage = randRot(baseImage)\n",
    "    mp.subplot(3,3,i+2)\n",
    "    mp.xlabel('Rotated')\n",
    "    mp.imshow(np.array(randImage),cmap='gray',vmin=0,vmax=255)\n",
    "mp.tight_layout()\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try random translations. These are performed with the `RandomAffine` transformation function, which includes a more general class of transformations (rotations, translations, shear, rescaling), but with the rest of the options turned off.\n",
    "\n",
    "The translations are performed as a fraction (0-1) of the entire image size. The x and y translations can be set to different values.\n",
    "\n",
    "#### Exercise:\n",
    "Rerun the code block below with several different values of `maxTrX` and/or `maxTrY`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maxTrX = 0.2\n",
    "maxTrY = 0.2\n",
    "randTr = tv.transforms.RandomAffine(0,translate=(maxTrX,maxTrY),resample=Image.BICUBIC)\n",
    "baseImage = Image.open(imageFiles[handClass][1])\n",
    "mp.subplots(3,3,figsize=(8,8))\n",
    "mp.subplot(3,3,1)\n",
    "mp.xlabel('Base Image')\n",
    "mp.imshow(np.array(baseImage),cmap='gray',vmin=0,vmax=255)\n",
    "for i in range(8):\n",
    "    randImage = randTr(baseImage)\n",
    "    arr = np.array(im)\n",
    "    mp.subplot(3,3,i+2)\n",
    "    mp.xlabel('Translated')\n",
    "    mp.imshow(np.array(randImage),cmap='gray',vmin=0,vmax=255)\n",
    "mp.tight_layout()\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next try adding random noise to the images. While the code below produces white noise, in real applications we could produce noise functions that better model specific imaging modalities.\n",
    "\n",
    "#### Exercise:\n",
    "Rerun the code block with different values of `noiseStrength`. A value of 0.5 means that the noise will be weighted equally to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseStrength = 0.15\n",
    "baseImage = Image.open(imageFiles[handClass][1])\n",
    "mp.subplots(3,3,figsize=(8,8))\n",
    "mp.subplot(3,3,1)\n",
    "mp.xlabel('Base Image')\n",
    "mp.imshow(np.array(baseImage),cmap='gray',vmin=0,vmax=255)\n",
    "for i in range(8):\n",
    "    noise = np.random.random((imageWidth,imageHeight))\n",
    "    arr = np.array(baseImage)*(1-noiseStrength)+255*noiseStrength*noise\n",
    "    mp.subplot(3,3,i+2)\n",
    "    mp.xlabel('Noise added')\n",
    "    mp.imshow(arr,cmap='gray',vmin=0,vmax=255)\n",
    "mp.tight_layout()\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "Replace `'Hand'` with another image class in the first code block, then rerun the other blocks to see how the transformations look with different source data. \n",
    "\n",
    "We define one final scaling function before we combine all these transformations and use them to augment the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleImage(x):\n",
    "    y = np.array(x)\n",
    "    if(np.min(y) < np.max(y)):  # Assuming the image isn't empty, rescale so its values run from 0 to 255\n",
    "        y = 255.0*(y - 1.0*np.min(y))/(1.0*np.max(y) - np.min(y))\n",
    "    z = Image.fromarray(np.uint8(y))\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your previous experiments, choose values for the parameters `maxRot`, `maxTrX`, `maxTrY`, and `noiseStrength` that will add some variability to the images without altering them unrecognizably. The code block below will augment each class of image using the combined transformations on randomly chosen source images until the target number of 15000 of each class is reached.\n",
    "\n",
    "#### NOTE!\n",
    "This code should only be run once, as it will create image files to augment the dataset. Use the code blocks above to try different parameter values before setting them below and executing the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPerClass = 15000\n",
    "maxRot = 30\n",
    "maxTrX = 0.2\n",
    "maxTrY = 0.2\n",
    "noiseStrength = 0.15\n",
    "randAff = tv.transforms.RandomAffine(maxRot,translate=(maxTrX,maxTrY),resample=Image.BICUBIC)\n",
    "for i in range(numClass):\n",
    "    print('Augmenting class',classNames[i])\n",
    "    for j in range(numPerClass - numEach[i]):\n",
    "        if j % 2000 == 0:\n",
    "            print('Adding image number',j)\n",
    "        imageID = np.random.randint(numEach[i])\n",
    "        baseImage = Image.open(imageFiles[i][imageID])\n",
    "        randImage = randAff(scaleImage(baseImage))\n",
    "        noise = np.random.random((imageWidth,imageHeight))\n",
    "        arr = np.array(randImage)*(1-noiseStrength)+255*noiseStrength*noise\n",
    "        finalImage = Image.fromarray(np.uint8(arr))\n",
    "        fname = imageFiles[i][imageID][:-5]+str(j)+'a.jpeg'\n",
    "        finalImage.save(fname)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check that the expected files were created by counting the number of images in each class now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFilesAug = [[os.path.join(dataDir,classNames[i],x) for x in os.listdir(os.path.join(dataDir,classNames[i]))]\n",
    "              for i in range(numClass)]                       # list of all files\n",
    "numEachAug = [len(imageFilesAug[i]) for i in range(numClass)]       # Count of each image class\n",
    "\n",
    "for i in range(numClass):\n",
    "    print(\"Category\",classNames[i],\"has\",numEachAug[i],\"images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code block below several times to see examples of both the augmented and original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.subplots(3,2,figsize=(8,8))\n",
    "for i in range(numClass):\n",
    "    imageID = np.random.randint(numEachAug[i])\n",
    "    im = Image.open(imageFilesAug[i][imageID])   # Randomly sample one image per class\n",
    "    arr = np.array(im)\n",
    "    mp.subplot(2,3,i+1)\n",
    "    if imageFilesAug[i][imageID][-6] == 'a':\n",
    "        imageType = ' Aug'\n",
    "    else:\n",
    "        imageType = ' Orig'\n",
    "    mp.xlabel('Class: '+classNames[i]+imageType)\n",
    "    mp.imshow(arr,cmap='gray',vmin=0,vmax=255)\n",
    "mp.tight_layout()\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a balanced and normalized dataset on which to perform your own deep learning experiments. If you'd like to download the dataset onto your laptop, first run the command below to zip the images into an archive (which will take 1 - 2 minutes). Then, click the link below to download the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf augmenteddata.tar.gz imagedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"augmenteddata.tar.gz\">Download your dataset!</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, if you aren't pleased with the results of your augmentation, you can erase them and restore a backup copy by running the code below. <b>Only run the following code block if you want to erase your augmented set!</b> After that, head back up a few cells to the code block where you executed the data augmentation, change the parameters, and give it another try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r imagedata\n",
    "!cp -r imagebackup imagedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When your dataset is ready, <a href=\"DSMedNIST.ipynb\">click here</a> to move on to the second part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
